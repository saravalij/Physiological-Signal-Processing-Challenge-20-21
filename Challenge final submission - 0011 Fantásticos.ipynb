{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting False Arrythmias in the ICU\n",
    "### - A Physiological Signal Processing Challenge -\n",
    "##### Los 0011 Fantásticos: Emilio Pareja Flores, Amanda Román Román y Sara Valiente Jaén"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this code, we aim to come up with a solution to detect arrythmias in ICUs in a more efficient way. Many times, a monitor raises an arrythmia alarm even though the patient being monitored is not having an arrythmia. This causes additional stress to both patients and medical staff in ICUs, hospital stay durations might be increased and the staff might be being worn off. Therefore, it is of great importance to improve detection algorithms.\n",
    "\n",
    "We have divided this notebook into sections so navigation is easier and the code is better understood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Importing neccesary libraries and modules\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from numpy.fft import *\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "!pip install biosppy\n",
    "from biosppy.signals.ecg import hamilton_segmenter\n",
    "from biosppy.signals.ecg import ecg\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from scipy.signal.windows import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Initial steps\n",
    "***\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Defined functions\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(path, file):\n",
    "    '''\n",
    "    This function takes as arguments a path and a file type \".hea\". \n",
    "    \n",
    "    The \".mat\" file associated to the passed file is found and some information is\n",
    "    extracted, such as the sampling frequency and the signal\\' labels.\n",
    "    \n",
    "    A loop is implemented in order to go over every label, every signal of the file, and\n",
    "    plot it using Matplotlib.\n",
    "    '''\n",
    "    \n",
    "    pat = loadmat(os.path.join(path,file[:-4]+'.mat'))\n",
    "    \n",
    "    with open(os.path.join(path,file)) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "    fs = int(lines[0].split()[2]) #hz\n",
    "    num_signals = int(lines[0].split()[1])\n",
    "\n",
    "    labels = []\n",
    "    for signal in lines[1:]:\n",
    "        #split the string and get the last which is the label\n",
    "        labels.append(signal.split()[-1])    \n",
    "    print(labels)\n",
    "    ind=len(labels)\n",
    "    #int(len(labels)/2)\n",
    "\n",
    "    signals = pat['val']\n",
    "\n",
    "    t = np.arange(len(signals[0]))/fs\n",
    "    \n",
    "    plt.figure(figsize=[12,10])\n",
    "    \n",
    "    for l in range(len(labels)):\n",
    "        plt.subplot(int('{}{}{}'.format(2,2,l+1)))\n",
    "        plt.plot(t,signals[l,:])\n",
    "        plt.title('{}'.format(labels[l]))\n",
    "        \n",
    "        \n",
    "    return None\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def periodogram(x,Nfft):\n",
    "    \n",
    "    N = len(x)\n",
    "    x_f = fft(x,Nfft) \n",
    "    Px = (np.abs(x_f)**2) / N\n",
    "    Px = fftshift(Px)\n",
    "    f = fftshift(fftfreq(Nfft))\n",
    "    return Px, f # periodogram of the signal and the frequencies it takes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Displaying different kinds of signals\n",
    "</div>\n",
    "\n",
    "Let's first plot different signals in order to assess visually what their differences might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True alarm, id 1\n",
    "\n",
    "path = '/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/training/'\n",
    "\n",
    "plot_signal(path,'1.hea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False alarm, id 4\n",
    "\n",
    "plot_signal(path,'4.hea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN mean heart rate, id 213\n",
    "\n",
    "plot_signal(path,'213.hea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN mean heart rate, id 363\n",
    "\n",
    "plot_signal(path,'363.hea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Initial filtering tests\n",
    "</div>\n",
    "Now, we are going to try to reduce noise and trends of a single signal applying filtering.\n",
    "\n",
    "First, we just plot an original signal. In this case, we take '101.hea'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_filename = '101.hea'\n",
    "pat = loadmat(os.path.join(path,pat_filename[:-4]+'.mat'))\n",
    "\n",
    "#get ECG\n",
    "\n",
    "with open(os.path.join(path,pat_filename)) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "#get fs\n",
    "fs = int(lines[0].split()[2]) #hz\n",
    "\n",
    "#number of signals\n",
    "num_signals = int(lines[0].split()[1])\n",
    "\n",
    "#get labels\n",
    "labels = []\n",
    "for signal in lines[1:]:\n",
    "    #split the string and get the last which is the label\n",
    "    labels.append(signal.split()[-1])\n",
    "    \n",
    "print(labels)\n",
    "\n",
    "#get signals\n",
    "signals = pat['val']\n",
    "\n",
    "#get one ECG signal\n",
    "l = len(signals[0])-10000\n",
    "\n",
    "t = np.arange(10000)/fs\n",
    "\n",
    "#plt.plot(t,signals[0,:1000])\n",
    "\n",
    "plt.figure(figsize=[15,8])\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(t,signals[0,l:]) # II signal\n",
    "plt.title('II signal')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(t,signals[1,l:]) # V signal\n",
    "plt.title('V signal')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(t,signals[2,l:]) # PLETH signal\n",
    "plt.title('PLETH signal')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(t,signals[3,l:]) # ABP signal\n",
    "plt.title('ABP signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we **detrend** the signal and apply a **bandpass** filter (between 0.5 and 40 Hz). The result is our **filtered** signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signals[0,:]\n",
    "sig_detrended = scipy.signal.detrend(sig)\n",
    "t = np.arange(len(sig))/fs\n",
    "\n",
    "\n",
    "f_low = 0.5        # Low cutoff frequency\n",
    "f_high = 40        # High cutoff frequency\n",
    "numtaps = 64       # Filter length\n",
    "b_bp = scipy.signal.firwin(numtaps, [f_low, f_high], pass_zero=False, fs=fs)     # Create FIR bandpass filter (0 DC gain)\n",
    "sig_f = scipy.signal.filtfilt(b_bp, 1, sig_detrended)    # Apply bandpass filter (detrended signals), denominator 1\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(t,sig)\n",
    "plt.plot(t,sig_detrended)\n",
    "plt.xlim([100,105])\n",
    "plt.legend(('Original II lead signal', 'Detrended'))\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(t,sig)\n",
    "plt.plot(t,sig_f)\n",
    "plt.xlim([100,105])\n",
    "plt.legend(('Original II lead signal', 'Detrended+BP'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the **periodogram** of the original and the filtered signals yields the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(sig)  # Length of the signal\n",
    "n_L = np.arange(0, L)\n",
    "nfft = 1024 # number of points of the FT\n",
    "\n",
    "P_sig, f_sig = periodogram (sig, nfft)     # Compute the periodogram (original signal)\n",
    "P_sig_f, f_sig_f = periodogram (sig_f, nfft)     # Compute the periodogram (filtered signal)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(n_L, sig)\n",
    "plt.plot(n_L, sig_f)\n",
    "plt.xlabel('$n$')\n",
    "plt.ylabel('Signal')\n",
    "plt.legend(('Original', 'Filtered'))\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(f_sig, 10*np.log10(P_sig))\n",
    "plt.plot(f_sig_f, 10*np.log10(P_sig_f))\n",
    "plt.title('Periodogram of the signal')\n",
    "plt.xlabel('Normalized frequency')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.legend(('Original', 'Filtered'))\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(f_sig, 10*np.log10(P_sig))\n",
    "plt.plot(f_sig_f, 10*np.log10(P_sig_f))\n",
    "plt.xlim(0, f_sig[-1])\n",
    "plt.title('Periodogram of the signal (only positive frequencies)')\n",
    "plt.xlabel('Normalized frequency')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.legend(('Original', 'Filtered'))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compare the obtained regular periodogram with the modified periodogram and the Welch's periodogram (all of the filtered signal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSD = []\n",
    "freqs = []\n",
    "\n",
    "sig_div = np.split(sig_f,100)\n",
    "\n",
    "L = len(sig_div[0])\n",
    "\n",
    "window = scipy.signal.windows.hamming(L,sym=False)\n",
    "\n",
    "for a in sig_div:\n",
    "    a_w = a * window\n",
    "    Px_window,f_window = periodogram(a_w,nfft)\n",
    "    PSD.append(Px_window)\n",
    "    freqs.append(f_window)\n",
    "\n",
    "Px_welch,f_welch = scipy.signal.welch(sig_f,fs=fs) \n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(f_sig_f, 10*np.log10(P_sig_f))\n",
    "plt.title('Periodogram')\n",
    "plt.xlabel('Normalized frequency')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "\n",
    "plt.subplot(312)\n",
    "#plt.plot(f_window, 10*np.log10(PSD).T)\n",
    "plt.plot(f_window, 10*np.log10(np.mean(PSD,axis=0)))\n",
    "plt.title('Modified periodogram (Hamming window)')\n",
    "plt.xlabel('Normalized frequency')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(f_welch, 10*np.log10(Px_welch))\n",
    "plt.title('Welch\\'s periodogram')\n",
    "plt.xlabel('Normalized frequency')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly seen that the modified periodogram is the one that has less noise associated. Therefore, in our code we will use the **modified periodogram (with a Hamming window)** to compute the power spectrum of the input sets signals.\n",
    "\n",
    "In order to do so, we partition the signal into 100 segments and compute their modified periodogram applying a Hamming window. The corresponding power is added to the array PSD, which we plot as the power spectrum of the signal. The total power is the sum of the all the powers (numbers) contained in the PSD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Working with the training data set\n",
    "***\n",
    "\n",
    "After having obtained a general idea of the signals we are working with and the filtering they need, we are ready to enter the input data set and start defining the parameters we are going to be looking at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Defined functions\n",
    "</div>\n",
    "\n",
    "These functions are, roughly, the **core of our project**. They plot and filter the signals, get information, compute parameters, get rid of useless and/or problematic values, and build the parameters array.\n",
    "\n",
    "The **parameters** which will be passed to the decisor in order to discriminate\n",
    "between true and false alarm are:\n",
    "    \n",
    "    - ECG: Mean heart rate\n",
    "    - ECG: Standard deviation of the heart rate\n",
    "    - ECG: Activity (Hjorth 0)\n",
    "    - ECG: Mobility (Hjorth 1)\n",
    "    - ECG: Complexity (Hjorth 2)\n",
    "    - ECG: Shannon entropy\n",
    "    - ABP: Total energy\n",
    "    - PLETH: Total energy\n",
    "    - RESP: Total energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram (ids_alarms,ids_params,title):\n",
    "    '''\n",
    "    Takes an array [[ids] [corresponding alarm number; 1 being true alarm and 0, false]],\n",
    "    another array [[ids] [parameter]] and a string called \"title\", which refers to the \n",
    "    parameter being studied (and passed to the function in ids_params as numbers).\n",
    "    \n",
    "    ids_alarms is converted into a dictionary to compare the ids (dictionary's keys) with\n",
    "    the ids_params' ids, so that the ids corresponding to a true alarm will have their\n",
    "    parameters stored in the list \"true\" and those corresponding to a false alarm, in \n",
    "    \"false\".\n",
    "    \n",
    "    Two histograms are plotted into a single figure: The one corresponding to true alarms\n",
    "    and the other one, to false alarms. That way, true alarms and false alarms's populations\n",
    "    are easily seen, and its overlapping can be visualized.\n",
    "    \n",
    "    Poor parameters will have the true and false populations almost completely overlapped.\n",
    "    '''\n",
    "    d = {}\n",
    "    true = []\n",
    "    false = []\n",
    "    p = 0\n",
    "    \n",
    "    for i,a in zip(ids_alarms[0],ids_alarms[1]):\n",
    "        d[i] = a\n",
    "         \n",
    "    for x in ids_params[0]:    \n",
    "        if d[x] == 1:\n",
    "            true.append(ids_params[1][p])\n",
    "        else:\n",
    "            false.append(ids_params[1][p])\n",
    "        p += 1\n",
    "            \n",
    "    plt.hist(true, 100, alpha=0.5, label='true alarm')\n",
    "    plt.hist(false, 100, alpha=0.5, label='false alarm')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def filter_it(signals,fs):\n",
    "    '''\n",
    "    Filters the passed signal as explained before: detrend + bandpass filter (0.4-50 Hz);\n",
    "    returns the filtered signal.\n",
    "    '''\n",
    "    \n",
    "    #sig = signals[0,:] # II lead???\n",
    "    sig=signals\n",
    "    sig_detrended = scipy.signal.detrend(sig)\n",
    "    t = np.arange(len(sig))/fs\n",
    "\n",
    "    f_low = 0.5        # Low cutoff frequency\n",
    "    f_high = 40        # High cutoff frequency\n",
    "    numtaps = 64       # Filter length\n",
    "    \n",
    "    b_bp = scipy.signal.firwin(numtaps, [f_low, f_high], pass_zero=False, fs=fs)     # Create FIR bandpass filter (0 DC gain)\n",
    "    sig_banddet = scipy.signal.filtfilt(b_bp, 1, sig_detrended) # bandpass and detrended\n",
    "    \n",
    "    return sig_banddet\n",
    "\n",
    "\n",
    "\n",
    "def hj_activity (array):\n",
    "    '''Computed Hjorth descriptor 0, which represents the total signal power.'''\n",
    "    \n",
    "    return np.var(array)\n",
    "\n",
    "\n",
    "\n",
    "def hj_mobility (array):\n",
    "    '''Computed Hjorth descriptor 1, which reflects the dominant frequency.'''\n",
    "    \n",
    "    return np.sqrt(np.divide(hj_activity(np.diff(array, axis=0)),hj_activity(array)))\n",
    "\n",
    "\n",
    "\n",
    "def hj_complexity (array):\n",
    "    '''Computed Hjorth descriptor 2, related to the bandwidth.'''\n",
    "    \n",
    "    return np.divide(hj_mobility(np.diff(array,axis=0)), hj_mobility(array))\n",
    "\n",
    "\n",
    "\n",
    "def compute_entropy(data):\n",
    "    '''Computed the Shannon entropy of the passed signal.'''\n",
    "    \n",
    "    prob1 = pd.value_counts(data) / len(data)\n",
    "    \n",
    "    return sum(np.log2(prob1) * prob1 * (-1))\n",
    " \n",
    "\n",
    "\n",
    "def get_parameters(pat,header,plot_flag = True):\n",
    "    \"\"\"\n",
    "    Gets the parameters which will be passed to the decisor in order to discriminate\n",
    "    between true and false alarm. These descriptors are:\n",
    "    \n",
    "        - ECG: Mean heart rate\n",
    "        - ECG: Standard deviation of the heart rate\n",
    "        - ECG: Activity (Hjorth 0)\n",
    "        - ECG: Mobility (Hjorth 1)\n",
    "        - ECG: Complexity (Hjorth 2)\n",
    "        - ECG: Shannon entropy\n",
    "        - ABP: Total energy\n",
    "        - PLETH: Total energy\n",
    "        - RESP: Total energy\n",
    "    \n",
    "    If the file being studied does not have ABP and/or PLETH and/or RESP signals,\n",
    "    the corresponding energy is set to zero.\n",
    "    \"\"\"\n",
    "\n",
    "    #Read header and get labels and signals, and from that extract one ECG signal\n",
    "\n",
    "    #ECG leads in the training set\n",
    "    ecg_lead = ['I', 'II', 'III', 'MCL','V','aVF', 'aVL','aVR']\n",
    "\n",
    "\n",
    "    #get fs\n",
    "    fs = int(header[0].split()[2]) #hz\n",
    "\n",
    "    #number of signals\n",
    "    num_signals = int(header[0].split()[1])\n",
    "    \n",
    "    #get labels\n",
    "    labels = []\n",
    "    for signal in header[1:]:\n",
    "    #split the string and get the last which is the label\n",
    "        labels.append(signal.split()[-1])\n",
    "\n",
    "\n",
    "    #get signals\n",
    "    signals = pat['val']\n",
    "\n",
    "   #find the ECG signals\n",
    "    idx_ecg = [labels.index(i) for i in ecg_lead if i in labels]\n",
    "\n",
    "        \n",
    "    #handle not enough beats\n",
    "    \n",
    "    try:\n",
    "        ts, filte,rpeaks, temp_ts,templates, hr_ts,hr = ecg(signal=signals[idx_ecg[0],:], sampling_rate=fs, show=False)\n",
    "    except:\n",
    "        print(\"Not enough beats\")\n",
    "        print(header[0].split()[0])\n",
    "        hr = 60\n",
    "        templates = 0\n",
    "        \n",
    "    mean_hr = np.mean(hr)\n",
    "    std_hr = np.std(hr)\n",
    "    \n",
    "    filtered = filter_it(signals[idx_ecg[0],:],fs) # ecg lead signal, filtered\n",
    "    \n",
    "    PSD = []\n",
    "    sig_div = np.split(filtered,100)\n",
    "\n",
    "    L = len(sig_div[0])\n",
    "    window = scipy.signal.windows.hamming(L,sym=False)\n",
    "\n",
    "    for a in sig_div:\n",
    "        a_w = a * window\n",
    "        Px_window,f_window = periodogram(a_w,nfft)\n",
    "        PSD.append(Px_window)\n",
    "        \n",
    "\n",
    "    total_power = np.sum(PSD)\n",
    "\n",
    "    activity = hj_activity(filtered)\n",
    "    mobility = hj_mobility(filtered)\n",
    "    complexity = hj_complexity(filtered)\n",
    "    \n",
    "    #entropy = scipy.stats.entropy(filtered)\n",
    "    entropy = compute_entropy(filtered)\n",
    "    \n",
    "    #plt.figure(figsize=[10,10])\n",
    "    if plot_flag:\n",
    "        \n",
    "        plt.subplot(311)\n",
    "        plt.plot(signals[idx_ecg[0],:])\n",
    "        plt.title('ECG lead')\n",
    "\n",
    "        plt.subplot(312)\n",
    "        plt.plot(np.arange(0,len(filtered)),filtered)\n",
    "        plt.title('ECG lead, filtered')\n",
    "        \n",
    "        plt.subplot(313)\n",
    "        # plt.plot(f_window,10*np.log10(Px_window))\n",
    "        plt.plot(f_window, 10*np.log10(np.mean(PSD,axis=0)))\n",
    "        plt.title('Power spectrum')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "    #find energies\n",
    "        \n",
    "    en_a=0\n",
    "    en_p=0\n",
    "    en_r=0\n",
    "        \n",
    "    for l in labels:\n",
    "        if l == 'ABP':\n",
    "            abp_signal = signals[labels.index(l),:]\n",
    "            en_a = sum(np.absolute(a)**2 for a in abp_signal)\n",
    "        elif l == 'PLETH':\n",
    "            pleth_signal = signals[labels.index(l),:]\n",
    "            en_p = sum(np.absolute(a)**2 for a in pleth_signal)\n",
    "        elif l == 'RESP':\n",
    "            resp_signal = signals[labels.index(l),:]\n",
    "            en_r = sum(np.absolute(a)**2 for a in resp_signal)\n",
    "        \n",
    "    \n",
    "    return mean_hr,std_hr,activity,mobility,complexity,entropy,en_a,en_p,en_r\n",
    "\n",
    "\n",
    "def clean_array(np_array):\n",
    "    ''' \n",
    "    This function aims to tackle nan, inf and -inf values. \n",
    "    \n",
    "    An array, containing problematic values, is passed; the same array is returned, but\n",
    "    without nan, positive and negative infinite values.\n",
    "    \n",
    "    Since different kinds of arrythmias are not to be detected, there is no distinction\n",
    "    between problematic values, they are all set to zero.\n",
    "    '''\n",
    "    \n",
    "    array_list = [] \n",
    "    clean = []\n",
    "\n",
    "    for i in range(len(np_array[0,:])):\n",
    "        array_list.append(np_array[:,i])\n",
    "\n",
    "    for array in array_list:\n",
    "        array = np.array(array,dtype='f')\n",
    "        clean.append(np.nan_to_num(array, copy=False, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "    clean = np.array(clean)\n",
    "    clean = clean.T\n",
    "    \n",
    "    return clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Reading data\n",
    "</div>\n",
    "\n",
    "Let us get into the training set and **compute the parameters** for each recording!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the possible labels in the training set\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/training/'):\n",
    "    filenames.sort()\n",
    "    j = 0\n",
    "    labels = []\n",
    "    \n",
    "    for filename in filenames:\n",
    "        if 'mat' in filename:\n",
    "            continue\n",
    "        clear_output(wait = True)\n",
    "        print(j,\" of \",len(filenames)/2)\n",
    "        j+=1\n",
    "        \n",
    "        with open(os.path.join(dirname,filename)) as f:\n",
    "                header = f.readlines()\n",
    "    \n",
    "        for signal in header[1:]:\n",
    "            #split the string and get the last which is the label\n",
    "            labels.append(signal.split()[-1])\n",
    "\n",
    "\n",
    "print(np.unique(labels))\n",
    "\n",
    "ecg_lead = ['I', 'II', 'III', 'MCL','V','aVF', 'aVL','aVR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get into the data folder\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "X = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/training/'):\n",
    "    filenames.sort()\n",
    "    j = 0\n",
    "    for filename in filenames[:]:\n",
    "        #print(filename)\n",
    "        \n",
    "        if j%5==0:\n",
    "            clear_output(wait = True)\n",
    "            print(j,\" of \",len(filenames)/2)\n",
    "            #print(filename)\n",
    "            \n",
    "        if 'mat' in filename:\n",
    "            continue\n",
    "\n",
    "        #read the pat data\n",
    "        j+=1\n",
    "        record = loadmat(os.path.join(dirname,filename[:-4]+'.mat'))\n",
    "        \n",
    "        #get the header\n",
    "        with open(os.path.join(dirname,filename)) as f:\n",
    "            header = f.readlines()\n",
    "\n",
    "        # get parameters\n",
    "        mean_hr,std_hr,activity,mobility,complexity,entropy,en_a,en_p,en_r=get_parameters(record,header,plot_flag = True)\n",
    "        \n",
    "        X.append([int(filename[:-4]),mean_hr,std_hr,activity,mobility,complexity,entropy,en_a,en_p,en_r])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Formatting the parameters list\n",
    "</div>\n",
    "\n",
    "The parameters list X contains nan,inf and -inf values which would raise errors later on in the code if they were not hadled. Consequently, X is passed to our previously defined function that gets rid of these values. \n",
    "\n",
    "The resulting array Z does not have problematic values but still has all the information that X stores. **Z is the array that will be passed to our decisor!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan and +/-inf handling:\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "Z = clean_array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Final steps of the training prediction\n",
    "</div>\n",
    "\n",
    "\n",
    "The array containing the ids and their corresponding 1 (true alarm) and 0 (false alarm) is built, and the histograms of some parameters are plotted in order to assess their efficacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get labels for the patients\n",
    "\n",
    "y = np.loadtxt('/kaggle/input/physiological-signals-processing-challenge-2021/alarms_training.csv',skiprows=1,delimiter = ',',usecols = [0,1])\n",
    "\n",
    "y_train = y[np.array(Z[:,0]-1,dtype = np.int32),:]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(Z[:,1].shape)\n",
    "print(y_train[:,1].shape)\n",
    "\n",
    "histogram(y_train.T,[Z[:,0],Z[:,1]],'mean_hr')\n",
    "histogram(y_train.T,[Z[:,0],Z[:,2]],'std_hr')\n",
    "histogram(y_train.T,[Z[:,0],Z[:,3]],'activity')\n",
    "histogram(y_train.T,[Z[:,0],Z[:,4]],'mobility')\n",
    "histogram(y_train.T,[Z[:,0],Z[:,5]],'complexity')\n",
    "histogram(y_train.T,[Z[:,0],Z[:,6]],'entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the **Naive Bayes decisor** is finally aseembled. It is trained through Z and y_train and then used to predict y_hat, predictions in terms of the training set. The accuracy is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#get priors\n",
    "\n",
    "P_h0 = np.mean(y_train[:,1] == 0)\n",
    "P_h1 = np.mean(y_train[:,1] == 1)\n",
    "\n",
    "print('P_h0:',P_h0,'; P_h1:',P_h1)\n",
    "\n",
    "#naive bayes model\n",
    "\n",
    "nb_detector = GaussianNB(priors = [P_h0,P_h1])\n",
    "\n",
    "#train the model\n",
    "\n",
    "nb_detector.fit(Z[:,1:],y_train[:,1])\n",
    "\n",
    "print(\"mean values n_classes, n_features\")\n",
    "print(nb_detector.theta_)\n",
    "\n",
    "print(\"variance values n_classes, n_features\")\n",
    "print(nb_detector.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our parameters obtained we can apply the following rule\n",
    "\n",
    "$$P(H_1|\\boldsymbol{x}) \\mathop{\\gtrless}^{D_1}_{D_0}P(H_0|\\boldsymbol{x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict first case\n",
    "'''\n",
    "x_1 = X[0,1:]\n",
    "\n",
    "D = nb_detector.predict(x_1[np.newaxis,:])\n",
    "\n",
    "print(X[0,0])\n",
    "print(y_train[0,0])\n",
    "print('Detection: %d'%D[0])\n",
    "print('Hypothesis H: %d' %y_train[0,1])\n",
    "'''\n",
    "\n",
    "#whole training set\n",
    "y_hat = nb_detector.predict(Z[:,1:])\n",
    "print(Z[:,1:].shape)\n",
    "\n",
    "print('ACC = %.2f'%np.mean(y_hat == y_train[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Working with the test data set\n",
    "***\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Reading data and getting parameters array\n",
    "</div>\n",
    "\n",
    "The above steps are implemented over the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's switch to test directory\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/physiological-signals-processing-challenge-2021/data_challenge/test/'):\n",
    "    filenames.sort()\n",
    "    j = 0\n",
    "    for filename in filenames:\n",
    "        #print(filename)\n",
    "        \n",
    "        if j%25==0:\n",
    "            clear_output(wait = True)\n",
    "            print(j,\" of \",len(filenames)/2)\n",
    "            #print(filename)\n",
    "            \n",
    "        if 'mat' in filename:\n",
    "            continue\n",
    "        #\n",
    "        j+=1\n",
    "        #read the pat data\n",
    "        record = loadmat(os.path.join(dirname,filename[:-4]+'.mat'))\n",
    "        \n",
    "        #get the header\n",
    "        with open(os.path.join(dirname,filename)) as f:\n",
    "            header = f.readlines()\n",
    "\n",
    "        \n",
    "        mean_hr,std_hr,activity,mobility,complexity,entropy,en_a,en_p,en_r= get_parameters(record,header,plot_flag = False)\n",
    "        \n",
    "        X_test.append([int(filename[:-4]),mean_hr,std_hr,activity,mobility,complexity,entropy,en_a,en_p,en_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle problematic values:\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Z_test = clean_array(X_test)\n",
    "\n",
    "# sort data\n",
    "\n",
    "idx_sort = np.argsort(Z_test[:,0])\n",
    "\n",
    "Z_test = Z_test[idx_sort,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Predicting and obtaining our final solution\n",
    "</div>\n",
    "\n",
    "Since our parameters were previously defined and assessed and our decisor was previously trained, we can jump to predict alarms of the data set recordings.\n",
    "\n",
    "**Our solution is created!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "\n",
    "y_hat_test = nb_detector.predict(Z_test[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat_test[:])\n",
    "\n",
    "#create solution\n",
    "\n",
    "df = pd.DataFrame({'Id': Z_test[:,0], 'Category': y_hat_test})\n",
    "df= df.astype(int)\n",
    "#df = df.astype({\"Id\": int, \"Category\": float})\n",
    "\n",
    "df.to_csv('submission_naive_bayes_final.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "***\n",
    "\n",
    "- Several StackOverflow issues\n",
    "- Numpy documentation\n",
    "- Scipy documentation\n",
    "- Biosppy documentation\n",
    "- [Hjorth descriptors alternative formulas](http://https://ruidera.uclm.es/xmlui/bitstream/handle/10578/15441/TFG-Luis%20Caba%c3%b1ero%20G%c3%b3mez.pdf?sequence=1&isAllowed=y)\n",
    "- [Feature extraction Kaggle notebook](http://https://www.kaggle.com/treina/feature-extractor-matlab2python-translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
